Both the slope and intercept from the optimization have the same value as their linear regression counterparts (at least to 2 decimal places).<br>
The optimization-based approach works well in this case, and would be preferred if we have a more complex model that does not have an analytical solution for the best fit. However, if the objective function has more than one local minima, optimization might produce a result that is not globally optimized and we would have difficulty detecting that. What's more, we cannot obtain confidence intervals from optimization alone.<br>
On the other hand, linear regression guarantees a best fit solution and also gives the confidence intervals for the best fit parameters. However, not every regression has an analytical best solution, so this approach is model-specific and cannot be generalized.
